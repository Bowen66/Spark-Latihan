{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79c90f6e-538b-4819-9610-38992ca06ad4",
   "metadata": {},
   "source": [
    "##Import library needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00b45745-b7d4-4f6a-b069-d55592f7c6dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2391dfe2-f7f7-462f-a785-0bd5c1cd121c",
   "metadata": {},
   "source": [
    "#Create Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31dcb65f-32e4-4e65-bd60-08cf14cf4ace",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a spark session\n",
    "spark = SparkSession.builder.appName(\"SparkSQL\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e93635fe-d382-45a1-9756-76800acf5967",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:===============================================>          (9 + 2) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is our inferred schema:\n",
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropOff_datetime: timestamp (nullable = true)\n",
      " |-- PUlocationID: integer (nullable = true)\n",
      " |-- DOlocationID: integer (nullable = true)\n",
      " |-- SR_Flag: integer (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\")\\\n",
    "    .csv(\"fhv_tripdata_2019-01.csv\")\n",
    "print(\"Here is our inferred schema:\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f22dc0d-f9d5-4d92-a1e3-0ff2fc44f5cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B00001|2019-01-01 00:30:00|2019-01-01 02:51:55|        null|        null|   null|                B00001|\n",
      "|              B00001|2019-01-01 00:45:00|2019-01-01 00:54:49|        null|        null|   null|                B00001|\n",
      "|              B00001|2019-01-01 00:15:00|2019-01-01 00:54:52|        null|        null|   null|                B00001|\n",
      "|              B00008|2019-01-01 00:19:00|2019-01-01 00:39:00|        null|        null|   null|                B00008|\n",
      "|              B00008|2019-01-01 00:27:00|2019-01-01 00:37:00|        null|        null|   null|                B00008|\n",
      "|              B00008|2019-01-01 00:48:00|2019-01-01 01:02:00|        null|        null|   null|                B00008|\n",
      "|              B00008|2019-01-01 00:50:00|2019-01-01 00:59:00|        null|        null|   null|                B00008|\n",
      "|              B00008|2019-01-01 00:51:00|2019-01-01 00:56:00|        null|        null|   null|                B00008|\n",
      "|              B00009|2019-01-01 00:44:00|2019-01-01 00:58:00|        null|        null|   null|                B00009|\n",
      "|              B00009|2019-01-01 00:19:00|2019-01-01 00:36:00|        null|        null|   null|                B00009|\n",
      "|              B00009|2019-01-01 00:36:00|2019-01-01 00:49:00|        null|        null|   null|                B00009|\n",
      "|              B00009|2019-01-01 00:26:00|2019-01-01 00:32:00|        null|        null|   null|                B00009|\n",
      "|              B00009|2019-01-01 00:26:00|2019-01-01 00:36:00|        null|        null|   null|                B00009|\n",
      "|              B00009|2019-01-01 00:58:00|2019-01-01 01:05:00|        null|        null|   null|                B00009|\n",
      "|              B00013|2019-01-01 00:02:29|2019-01-02 00:25:30|        null|        null|   null|                B00013|\n",
      "|              B00013|2019-01-01 00:01:33|2019-01-02 00:18:16|        null|        null|   null|                B00013|\n",
      "|              B00037|2019-01-01 00:02:43|2019-01-01 00:10:14|        null|         265|   null|                B00037|\n",
      "|              B00037|2019-01-01 00:26:02|2019-01-01 00:37:00|        null|         265|   null|                B00037|\n",
      "|              B00037|2019-01-01 00:11:16|2019-01-01 00:25:41|        null|         265|   null|                B00037|\n",
      "|              B00037|2019-01-01 00:33:45|2019-01-01 00:45:28|        null|         265|   null|                B00037|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "359006ac-0797-4de6-800c-1d788ea4a939",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"tripData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ab3fa84-2e45-4974-a929-90a6cd726797",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:==============================================>          (9 + 2) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+----------------+\n",
      "|dispatching_base_num|pickup_datetime|dropoff_datetime|\n",
      "+--------------------+---------------+----------------+\n",
      "+--------------------+---------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlDF = spark.sql(\"SELECT DISTINCT dispatching_base_num,  pickup_datetime, dropoff_datetime FROM \\\n",
    "tripData where PULocationID is not null and DOLocationID ='264' and dispatching_base_num= 'B02182' \\\n",
    "GROUP BY dispatching_base_num,  pickup_datetime, dropoff_datetime ORDER BY pickup_datetime ASC\")\n",
    "sqlDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22dc5f21-03f3-4c42-aa0d-f9a977992b21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:==============================================>          (9 + 2) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|SR_Flag|\n",
      "+-------+\n",
      "|     26|\n",
      "|     27|\n",
      "|     12|\n",
      "|     22|\n",
      "|   null|\n",
      "|      1|\n",
      "|     13|\n",
      "|      6|\n",
      "|     16|\n",
      "|      3|\n",
      "|     20|\n",
      "|      5|\n",
      "|     19|\n",
      "|     15|\n",
      "|      9|\n",
      "|     17|\n",
      "|      4|\n",
      "|      8|\n",
      "|     23|\n",
      "|      7|\n",
      "+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_distinct = spark.sql(\"SELECT DISTINCT SR_Flag from tripData where PULocationID IS NOT NULL and DOLocationID is NOT NULL \")\n",
    "df_distinct.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21ec99a3-fed4-4102-a149-da8220e8088a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sqlDF.write.parquet(\"spark_write_parquet.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70a93a3e-dc3d-4f14-912f-8ab677a19f0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+----------------+\n",
      "|dispatching_base_num|pickup_datetime|dropoff_datetime|\n",
      "+--------------------+---------------+----------------+\n",
      "+--------------------+---------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_parquet = spark.read.parquet(\"spark_write_parquet.parquet\")\n",
    "df_parquet.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "240e548a-f001-495c-9c2d-5b65258904cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:>                                                         (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+------------+----------------------+\n",
      "|dispatching_base_num|PUlocationID|DOlocationID|Affiliated_base_number|\n",
      "+--------------------+------------+------------+----------------------+\n",
      "|     B00021         |          56|          70|       B00021         |\n",
      "|     B00021         |           7|         202|       B00021         |\n",
      "|     B00021         |          92|          92|       B00021         |\n",
      "|     B00021         |         223|         146|       B00021         |\n",
      "|     B00021         |          56|          56|       B00021         |\n",
      "|     B00021         |           7|         140|       B00021         |\n",
      "|     B00021         |         129|         260|       B00021         |\n",
      "|     B00021         |          83|         129|       B00021         |\n",
      "|     B00021         |         196|          56|       B00021         |\n",
      "|     B00021         |         173|          83|       B00021         |\n",
      "|     B00021         |          82|          93|       B00021         |\n",
      "|     B00021         |         226|           7|       B00021         |\n",
      "|     B00021         |         130|         130|       B00021         |\n",
      "|     B00021         |         146|           7|       B00021         |\n",
      "|     B00021         |         129|          56|       B00021         |\n",
      "|     B00021         |         129|         207|       B00021         |\n",
      "|     B00021         |          89|          89|       B00021         |\n",
      "|     B00021         |          70|         173|       B00021         |\n",
      "|     B00021         |         179|           7|       B00021         |\n",
      "|     B00021         |          73|          92|       B00021         |\n",
      "+--------------------+------------+------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sqlTripData = spark.sql(\"SELECT dispatching_base_num, PUlocationID, DOlocationID, Affiliated_base_number \\\n",
    "FROM tripData WHERE PULocationID IS NOT NULL and DOLocationID is NOT NULL AND pickup_datetime >= '2019-01-01' \\\n",
    "AND pickup_datetime <='2019-01-10' GROUP BY dispatching_base_num, PUlocationID, DOlocationID, Affiliated_base_number \\\n",
    "ORDER BY dispatching_base_num\")\n",
    "sqlTripData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86751e30-480d-4386-b5f7-dc25d19a4a54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4587b4bd019793f4c85e76e35f2c6c661f5b9abb7c3c148f1b228f28efe70e01"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
